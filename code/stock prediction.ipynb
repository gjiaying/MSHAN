{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5928,
     "status": "ok",
     "timestamp": 1617915631940,
     "user": {
      "displayName": "Jiaying Gong",
      "photoUrl": "",
      "userId": "05239074792950850512"
     },
     "user_tz": 240
    },
    "id": "LsAXpV1FuPb0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import re\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import tree\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tensorflow_addons as tfa\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "from keras.layers.recurrent import LSTM,GRU\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "from tcn import TCN, tcn_full_summary\n",
    "from keras_multi_head import MultiHead\n",
    "from keras_multi_head import MultiHeadAttention\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from spektral.layers import GCNConv\n",
    "from spektral.models.gcn import GCN\n",
    "#from transformers import BertTokenizer, TFBertModel, BertConfig\n",
    "#nltk.download('stopwords')\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "classifier = TextClassifier.load('en-sentiment')\n",
    "#embed = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "#stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3052,
     "status": "ok",
     "timestamp": 1617915641973,
     "user": {
      "displayName": "Jiaying Gong",
      "photoUrl": "",
      "userId": "05239074792950850512"
     },
     "user_tz": 240
    },
    "id": "PUedkUx_HuH_",
    "outputId": "ba9475f7-a674-4175-e3a7-c693b2b1e6cb"
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(os.getcwd()+'/price/alltrainings.csv')\n",
    "X_test = pd.read_csv(os.getcwd()+'/price/alltestings.csv')\n",
    "X_val = pd.read_csv(os.getcwd()+'/price/allvalidations.csv')\n",
    "#X = X.drop(X.columns[0], axis=1)\n",
    "#X_test = X_test.drop(X_test.columns[0], axis=1)\n",
    "#X_val = X_val.drop(X_val.columns[0], axis=1)\n",
    "y = X['label']\n",
    "y_test = X_test['label']\n",
    "y_val = X_val['label']\n",
    "#baseline1\n",
    "#X = X[['date','adj close','high','low','label']]\n",
    "#X_val = X_val[['date','adj close','high','low','label']]\n",
    "#X_test = X_test[['date','adj close','high','low','label']]\n",
    "\n",
    "#baseline3 L1 regularization\n",
    "#X = X[['date','adj close','high','low','open','close','volume','volume_nvi','trend_adx_pos','trend_mass_index','trend_cci','trend_aroon_up','trend_aroon_down','trend_aroon_ind','momentum_rsi','momentum_stoch','momentum_wr','RSI','Stoch','stoch_signal','TSI','WilliamsR','adx_neg','aroon_down','aroon','aroon_up','MI','CR','label']]\n",
    "#X_test = X_test[['date','adj close','high','low','open','close','volume','volume_nvi','trend_adx_pos','trend_mass_index','trend_cci','trend_aroon_up','trend_aroon_down','trend_aroon_ind','momentum_rsi','momentum_stoch','momentum_wr','RSI','Stoch','stoch_signal','TSI','WilliamsR','adx_neg','aroon_down','aroon','aroon_up','MI','CR','label']]\n",
    "\n",
    "#X = X[['date','adj close','high','low','open','close','volume','volume_nvi', 'volatility_atr', 'volatility_bbw', 'volatility_dchi', 'trend_macd', 'trend_macd_signal', 'trend_adx', 'trend_adx_pos', 'trend_adx_neg', 'trend_mass_index', 'trend_cci', 'trend_dpo', 'trend_kst_diff', 'trend_aroon_up', 'momentum_rsi', 'momentum_mfi', 'momentum_uo', 'momentum_stoch_signal', 'momentum_wr', 'momentum_ao', 'momentum_roc', 'others_dlr', 'others_cr', 'AO', 'MFI', 'ROC', 'RSI', 'stoch_signal', 'UO', 'WilliamsR', 'NVI', 'ATR', 'bb_bbw', 'dc_dchi', 'adx', 'adx_neg', 'aroon_up', 'CCI', 'DPO', 'KST', 'KST_diff', 'macd', 'macd_sig', 'MI', 'CR', 'DLR','label']]\n",
    "#X_val = X_val[['date','adj close','high','low','open','close','volume','volume_nvi', 'volatility_atr', 'volatility_bbw', 'volatility_dchi', 'trend_macd', 'trend_macd_signal', 'trend_adx', 'trend_adx_pos', 'trend_adx_neg', 'trend_mass_index', 'trend_cci', 'trend_dpo', 'trend_kst_diff', 'trend_aroon_up', 'momentum_rsi', 'momentum_mfi', 'momentum_uo', 'momentum_stoch_signal', 'momentum_wr', 'momentum_ao', 'momentum_roc', 'others_dlr', 'others_cr', 'AO', 'MFI', 'ROC', 'RSI', 'stoch_signal', 'UO', 'WilliamsR', 'NVI', 'ATR', 'bb_bbw', 'dc_dchi', 'adx', 'adx_neg', 'aroon_up', 'CCI', 'DPO', 'KST', 'KST_diff', 'macd', 'macd_sig', 'MI', 'CR', 'DLR','label']]\n",
    "#X_test = X_test[['date','adj close','high','low','open','close','volume','volume_nvi', 'volatility_atr', 'volatility_bbw', 'volatility_dchi', 'trend_macd', 'trend_macd_signal', 'trend_adx', 'trend_adx_pos', 'trend_adx_neg', 'trend_mass_index', 'trend_cci', 'trend_dpo', 'trend_kst_diff', 'trend_aroon_up', 'momentum_rsi', 'momentum_mfi', 'momentum_uo', 'momentum_stoch_signal', 'momentum_wr', 'momentum_ao', 'momentum_roc', 'others_dlr', 'others_cr', 'AO', 'MFI', 'ROC', 'RSI', 'stoch_signal', 'UO', 'WilliamsR', 'NVI', 'ATR', 'bb_bbw', 'dc_dchi', 'adx', 'adx_neg', 'aroon_up', 'CCI', 'DPO', 'KST', 'KST_diff', 'macd', 'macd_sig', 'MI', 'CR', 'DLR','label']]\n",
    "\n",
    "\n",
    "#baseline3 L1+MBR\n",
    "X = X[['date','adj close','high','low','open','close','volume','volume_nvi','trend_adx_pos','trend_mass_index','trend_cci','momentum_rsi','momentum_stoch','momentum_wr','RSI','Stoch','stoch_signal','TSI','WilliamsR','adx_neg','MI','CR','label']]\n",
    "X_test = X_test[['date','adj close','high','low','open','close','volume','volume_nvi','trend_adx_pos','trend_mass_index','trend_cci','momentum_rsi','momentum_stoch','momentum_wr','RSI','Stoch','stoch_signal','TSI','WilliamsR','adx_neg','MI','CR','label']]\n",
    "X_val = X_val[['date','adj close','high','low','open','close','volume','volume_nvi','trend_adx_pos','trend_mass_index','trend_cci','momentum_rsi','momentum_stoch','momentum_wr','RSI','Stoch','stoch_signal','TSI','WilliamsR','adx_neg','MI','CR','label']]\n",
    "\n",
    "#X = X[['date','adj close','high','low','open','close','volume','volume_nvi','trend_adx','trend_adx_pos','trend_adx_neg','trend_mass_index','trend_cci','trend_dpo','trend_kst_diff','momentum_mfi','momentum_uo','momentum_wr','momentum_roc','others_dlr','others_cr','MFI','stoch_signal','UO','WilliamsR','NVI','adx','adx_neg','DPO','KST','KST_diff','MI','CR','DLR','label']]\n",
    "#X_val = X_val[['date','adj close','high','low','open','close','volume','volume_nvi','trend_adx','trend_adx_pos','trend_adx_neg','trend_mass_index','trend_cci','trend_dpo','trend_kst_diff','momentum_mfi','momentum_uo','momentum_wr','momentum_roc','others_dlr','others_cr','MFI','stoch_signal','UO','WilliamsR','NVI','adx','adx_neg','DPO','KST','KST_diff','MI','CR','DLR','label']]\n",
    "#X_test = X_test[['date','adj close','high','low','open','close','volume','volume_nvi','trend_adx','trend_adx_pos','trend_adx_neg','trend_mass_index','trend_cci','trend_dpo','trend_kst_diff','momentum_mfi','momentum_uo','momentum_wr','momentum_roc','others_dlr','others_cr','MFI','stoch_signal','UO','WilliamsR','NVI','adx','adx_neg','DPO','KST','KST_diff','MI','CR','DLR','label']]\n",
    "\n",
    "#baseline3 L1+MBR+RFE\n",
    "#X = X[['date','adj close','high','low','open','close','volume','trend_adx_pos','trend_mass_index','momentum_rsi','momentum_stoch','momentum_wr','RSI','Stoch','TSI','WilliamsR','MI','label']]\n",
    "#X_test = X_test[['date','adj close','high','low','open','close','volume','trend_adx_pos','trend_mass_index','momentum_rsi','momentum_stoch','momentum_wr','RSI','Stoch','TSI','WilliamsR','MI','label']]\n",
    "#X_val = X_val[['date','adj close','high','low','open','close','volume','trend_adx_pos','trend_mass_index','momentum_rsi','momentum_stoch','momentum_wr','RSI','Stoch','TSI','WilliamsR','MI','label']]\n",
    "#X = X[['date','adj close','high','low','open','close','volume', 'volume_nvi', 'trend_adx', 'trend_adx_pos', 'trend_adx_neg', 'trend_mass_index', 'trend_cci', 'trend_dpo', 'trend_kst_diff', 'momentum_mfi', 'momentum_uo', 'momentum_wr', 'momentum_roc', 'others_dlr', 'others_cr', 'MFI', 'stoch_signal', 'UO', 'WilliamsR', 'NVI', 'adx', 'adx_neg', 'KST', 'KST_diff', 'MI', 'CR', 'DLR','label']]\n",
    "#X_val = X_val[['date','adj close','high','low','open','close','volume', 'volume_nvi', 'trend_adx', 'trend_adx_pos', 'trend_adx_neg', 'trend_mass_index', 'trend_cci', 'trend_dpo', 'trend_kst_diff', 'momentum_mfi', 'momentum_uo', 'momentum_wr', 'momentum_roc', 'others_dlr', 'others_cr', 'MFI', 'stoch_signal', 'UO', 'WilliamsR', 'NVI', 'adx', 'adx_neg', 'KST', 'KST_diff', 'MI', 'CR', 'DLR','label']]\n",
    "#X_test = X_test[['date','adj close','high','low','open','close','volume', 'volume_nvi', 'trend_adx', 'trend_adx_pos', 'trend_adx_neg', 'trend_mass_index', 'trend_cci', 'trend_dpo', 'trend_kst_diff', 'momentum_mfi', 'momentum_uo', 'momentum_wr', 'momentum_roc', 'others_dlr', 'others_cr', 'MFI', 'stoch_signal', 'UO', 'WilliamsR', 'NVI', 'adx', 'adx_neg', 'KST', 'KST_diff', 'MI', 'CR', 'DLR','label']]\n",
    "\n",
    "#baseline3 MBR\n",
    "#X = X[['date','adj close','high','low','open','close','volume','MI','trend_mass_index','CMF','volume_cmf','trend_dpo','DPO','trend_vortex_ind_neg','momentum_uo','momentum_mfi','adx_pos','label']]\n",
    "#X_test = X_test[['date','adj close','high','low','open','close','volume','MI','trend_mass_index','CMF','volume_cmf','trend_dpo','DPO','trend_vortex_ind_neg','momentum_uo','momentum_mfi','adx_pos','label']]\n",
    "#X = X[['date','adj close','high','low','open','close','volume','volume_adi','volume_obv','volume_cmf','volume_fi','volume_em','volume_vpt','volume_nvi','volatility_atr','trend_adx','trend_adx_pos','trend_adx_neg','trend_vortex_ind_pos','trend_vortex_ind_neg','trend_vortex_ind_diff','trend_mass_index','trend_cci','trend_dpo','trend_kst_diff','momentum_rsi','momentum_mfi','momentum_uo','momentum_stoch_signal','momentum_roc','others_cr','MFI','ROC','RSI','stoch_signal','UO','ADI','CMF','EoM','FI','NVI','OBV','VPT','adx','adx_neg','adx_pos','CCI','DPO','KST_diff','MI','vi_diff','vi_neg','vi_pos','CR','label']]\n",
    "#X_val = X_val[['date','adj close','high','low','open','close','volume','volume_adi','volume_obv','volume_cmf','volume_fi','volume_em','volume_vpt','volume_nvi','volatility_atr','trend_adx','trend_adx_pos','trend_adx_neg','trend_vortex_ind_pos','trend_vortex_ind_neg','trend_vortex_ind_diff','trend_mass_index','trend_cci','trend_dpo','trend_kst_diff','momentum_rsi','momentum_mfi','momentum_uo','momentum_stoch_signal','momentum_roc','others_cr','MFI','ROC','RSI','stoch_signal','UO','ADI','CMF','EoM','FI','NVI','OBV','VPT','adx','adx_neg','adx_pos','CCI','DPO','KST_diff','MI','vi_diff','vi_neg','vi_pos','CR','label']]\n",
    "#X_test = X_test[['date','adj close','high','low','open','close','volume','volume_adi','volume_obv','volume_cmf','volume_fi','volume_em','volume_vpt','volume_nvi','volatility_atr','trend_adx','trend_adx_pos','trend_adx_neg','trend_vortex_ind_pos','trend_vortex_ind_neg','trend_vortex_ind_diff','trend_mass_index','trend_cci','trend_dpo','trend_kst_diff','momentum_rsi','momentum_mfi','momentum_uo','momentum_stoch_signal','momentum_roc','others_cr','MFI','ROC','RSI','stoch_signal','UO','ADI','CMF','EoM','FI','NVI','OBV','VPT','adx','adx_neg','adx_pos','CCI','DPO','KST_diff','MI','vi_diff','vi_neg','vi_pos','CR','label']]\n",
    "\n",
    "#baseline2\n",
    "#X = X.drop(['Daily Percentage Change', 'Daily Change', 'prev adj close', 'y_t','label'], axis = 1)\n",
    "#X_val = X_val.drop(['Daily Percentage Change', 'Daily Change', 'prev adj close', 'y_t'], axis = 1)\n",
    "#X_test = X_test.drop(['Daily Percentage Change', 'Daily Change', 'prev adj close', 'y_t'], axis = 1)\n",
    "X = X.set_index('date')\n",
    "X_test = X_test.set_index('date')\n",
    "X_val = X_val.set_index('date')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1617820759943,
     "user": {
      "displayName": "Jiaying Gong",
      "photoUrl": "",
      "userId": "05239074792950850512"
     },
     "user_tz": 240
    },
    "id": "SZkCo21yjK_P"
   },
   "source": [
    "def linear_selector(data, labels):\n",
    "    lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(data, labels)\n",
    "    model = SelectFromModel(lsvc, prefit=True)\n",
    "    model.transform(data)\n",
    "    return data[data.columns[model.get_support(indices=True)]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 516082,
     "status": "ok",
     "timestamp": 1617916162161,
     "user": {
      "displayName": "Jiaying Gong",
      "photoUrl": "",
      "userId": "05239074792950850512"
     },
     "user_tz": 240
    },
    "id": "896_Tcqtm4pF",
    "outputId": "0e6e3da2-a017-4471-ca68-a6a3bcc0042c"
   },
   "source": [
    "names = X.columns.values.tolist()\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1617916162453,
     "user": {
      "displayName": "Jiaying Gong",
      "photoUrl": "",
      "userId": "05239074792950850512"
     },
     "user_tz": 240
    },
    "id": "pM6xqVt-mvJS"
   },
   "source": [
    "def pretty_print_linear(coefs, names = names):\n",
    "  lst = zip(coefs, names)\n",
    "  lst = sorted(lst, key = lambda x:abs(x[0]), reverse = True)\n",
    "  return \" + \".join(\"%s * %s\" % (round(coef, 4), name) for coef, name in lst)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "executionInfo": {
     "elapsed": 3104,
     "status": "ok",
     "timestamp": 1617916165286,
     "user": {
      "displayName": "Jiaying Gong",
      "photoUrl": "",
      "userId": "05239074792950850512"
     },
     "user_tz": 240
    },
    "id": "0qUsgwiEmao_"
   },
   "source": [
    "list = sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names),reverse=True)\n",
    "print(list)\n",
    "list1 = []\n",
    "for i in range(len(names)):\n",
    "  if rf.feature_importances_[i] >= 0.02 and names[i] != 'close' and names[i] != 'open' and names[i] != 'high' and names[i] != 'low' and names[i] != 'volume':\n",
    "            #print (names[i])\n",
    "    list1.append(names[i])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "names = X.columns.values.tolist()\n",
    "estimator = LinearRegression()\n",
    "rfe = RFECV(estimator, min_features_to_select = 21, step=1, cv=5)\n",
    "rfe.fit(X,y)\n",
    "list1=[]\n",
    "list = sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), names))\n",
    "\n",
    "for i in range(len(names)):\n",
    "    if rfe.ranking_[i] == 1 and names[i] != 'close' and names[i] != 'open' and names[i] != 'high' and names[i] != 'low' and names[i] != 'volume':\n",
    "        print (names[i])\n",
    "        list1.append(names[i])\n",
    "print(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1617821155654,
     "user": {
      "displayName": "Jiaying Gong",
      "photoUrl": "",
      "userId": "05239074792950850512"
     },
     "user_tz": 240
    },
    "id": "ZNzA-09O8Nb4",
    "outputId": "a16a7230-0715-454c-e4fe-2c9fd444a58d"
   },
   "outputs": [],
   "source": [
    "normalized_X = X\n",
    "mean = X.mean(axis = 0)\n",
    "normalized_X -= mean\n",
    "std = normalized_X.std(axis=0)\n",
    "normalized_X /= std\n",
    "\n",
    "normalized_X_test = X_test.astype(float)\n",
    "mean = X_test.mean(axis = 0)\n",
    "normalized_X_test -= mean\n",
    "std = normalized_X_test.std(axis=0)\n",
    "normalized_X_test /= std\n",
    "\n",
    "normalized_X_val = X_val.astype(float)\n",
    "mean = X_val.mean(axis = 0)\n",
    "normalized_X_val -= mean\n",
    "std = normalized_X_val.std(axis=0)\n",
    "normalized_X_val /= std\n",
    "\n",
    "normalized_X = normalized_X.drop('label', axis = 1)\n",
    "norm_X = normalized_X.copy()\n",
    "\n",
    "normalized_X_test = normalized_X_test.drop('label', axis = 1)\n",
    "norm_X_test = normalized_X_test.copy()\n",
    "\n",
    "normalized_X_val = normalized_X_val.drop('label', axis = 1)\n",
    "norm_X_val = normalized_X_val.copy()\n",
    "\n",
    "\n",
    "normalized_X = normalized_X.values\n",
    "normalized_X_test = normalized_X_test.values\n",
    "normalized_X_val = normalized_X_val.values\n",
    "norm_X = norm_X.values\n",
    "norm_X_test = norm_X_test.values\n",
    "norm_X_val = norm_X_val.values\n",
    "norm_X = np.expand_dims(norm_X, axis = 1)\n",
    "print(norm_X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 570,
     "status": "ok",
     "timestamp": 1617821158944,
     "user": {
      "displayName": "Jiaying Gong",
      "photoUrl": "",
      "userId": "05239074792950850512"
     },
     "user_tz": 240
    },
    "id": "NVRp_pODyeJN"
   },
   "outputs": [],
   "source": [
    "windows = 5\n",
    "lstm_input=[]\n",
    "for i in range(len(norm_X)-windows):\n",
    "  lstm_input.append(norm_X[i:i+windows,:])\n",
    "lstm_input=np.array(lstm_input)\n",
    "y = y[windows:]\n",
    "lstm_input = np.squeeze(lstm_input,axis=2)\n",
    "print(lstm_input.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "norm_X_test = np.expand_dims(norm_X_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_X_test = np.expand_dims(norm_X_test, axis = 1)\n",
    "norm_X_test_input=[]\n",
    "for i in range(len(norm_X_test)-windows):\n",
    "  norm_X_test_input.append(norm_X_test[i:i+windows,:])\n",
    "norm_X_test_input=np.array(norm_X_test_input)\n",
    "print(norm_X_test_input.shape)\n",
    "norm_X_test_input = np.squeeze(norm_X_test_input,axis=2)\n",
    "print(norm_X_test_input.shape)\n",
    "y_test = y_test[windows:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_X_val = np.expand_dims(norm_X_val, axis = 1)\n",
    "print(norm_X_val.shape)\n",
    "norm_X_val_input=[]\n",
    "for i in range(len(norm_X_val)-windows):\n",
    "  norm_X_val_input.append(norm_X_val[i:i+windows,:])\n",
    "norm_X_val_input=np.array(norm_X_val_input)\n",
    "print(norm_X_val_input.shape)\n",
    "norm_X_val_input = np.squeeze(norm_X_val_input,axis=2)\n",
    "print(norm_X_val_input.shape)\n",
    "y_val = y_val[windows:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 50\n",
    "EMBEDDING_DIMENSION = 512\n",
    "WINDOWS = 5\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(company, date):\n",
    "    str = company + '/' + date\n",
    "    filepath = os.getcwd() + '/tweet/preprocessed/' + str\n",
    "    list = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line)\n",
    "            list.append(data['text'])\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(tweet):\n",
    "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) #Remove @ sign\n",
    "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
    "    tweet = \" \".join(tweet.split())\n",
    "    #tweet = tweet.replace(\"#\", \"\").replace(\"_\", \"\").replace(\"$\", \"\") #Remove hashtag sign but keep the text\n",
    "    tweet = tweet.replace(\"rt\", \"\").replace(\"AT _ USER\", \"\").replace(\"URL\", \"\")\n",
    "    words = tweet.split()\n",
    "    wordsnew = tweet.split()\n",
    "    for i in range(len(words)):       \n",
    "        if '$' == words[i]:\n",
    "         \n",
    "            wordsnew = wordsnew[:i+1] + wordsnew[i + 2:]\n",
    "    \n",
    "    tweet = TreebankWordDetokenizer().detokenize(wordsnew)\n",
    "    tweet = tweet.replace(\"-\",\"\").replace(\"$\",\"\")\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    filepath_com = os.getcwd() + '/price/test_sample/'\n",
    "    company = os.listdir(filepath_com)\n",
    "\n",
    "    total_list = []\n",
    "    for i in range(len(company[:-1])):   #len(company[:-1])\n",
    "        filepath_date = os.getcwd() + '/tweet/preprocessed/' + str(company[i][:-4])\n",
    "        X = pd.read_csv(os.getcwd()+'/price/' + path + str(company[i]))\n",
    "        date = os.listdir(filepath_date)\n",
    "        \n",
    "        for j in range(len(date)): #len(date)-1\n",
    "            if date[j] in X['date'].values.tolist() and date[j][:-4] is not '.ipynb_checkpo':\n",
    "                #print(date[j])\n",
    "                list_oneday = []\n",
    "                list_oneday_score = []\n",
    "                list = preprocessing(company[i][:-4], date[j])\n",
    "                for k in range(len(list)):\n",
    "                    sentence = Sentence(TreebankWordDetokenizer().detokenize(list[k]))\n",
    "                    #print(sentence)\n",
    "                    #print(cleaner(str(sentence)))\n",
    "                    classifier.predict(sentence)\n",
    "                    \n",
    "                    list_oneday_score.append(sentence.labels[0].score)\n",
    "                    oneday = (embed(list[k]))\n",
    "                    \n",
    "                    if oneday.shape[0] >= MAX_LENGTH:\n",
    "                        list_oneday.append(oneday[0:MAX_LENGTH])\n",
    "                    else:\n",
    "                        one_as_vector = tf.reshape(oneday,[-1])\n",
    "                        zero_paddings = tf.zeros([MAX_LENGTH*EMBEDDING_DIMENSION]-tf.shape(one_as_vector),dtype=oneday.dtype)\n",
    "                        oneday_padded = tf.concat([one_as_vector, zero_paddings], 0)\n",
    "                        results = tf.reshape(oneday_padded, [MAX_LENGTH, EMBEDDING_DIMENSION])\n",
    "   \n",
    "           \n",
    "            \n",
    "                        list_oneday.append(results)\n",
    "                \n",
    "                list_oneday_score = np.array(list_oneday_score)\n",
    "                list_oneday_score = list_oneday_score/sum(list_oneday_score)\n",
    "                res = list_oneday * list_oneday_score[:, np.newaxis, np.newaxis]\n",
    "                #list_oneday = list_oneday*list_oneday_score\n",
    "                list_oneday = tf.convert_to_tensor(res)\n",
    "                #print(list_oneday)\n",
    "                \n",
    "               \n",
    "                list_oneday = np.mean(list_oneday,axis=0)\n",
    "                list_oneday = tf.convert_to_tensor(list_oneday)\n",
    "                \n",
    "                total_list.append(list_oneday)\n",
    "        #print(len(total_list))\n",
    "    total_list = tf.convert_to_tensor(total_list)\n",
    "    #gru = tf.keras.layers.GRU(64)\n",
    "    #total_list = (gru(total_list))\n",
    "    print(total_list.shape)\n",
    "    #np.save('embeddings.npy', embed(list[0]))\n",
    "    #all_embeddings = np.load('embeddings.npy')\n",
    "    #print(torch.FloatTensor(np.asarray(all_embeddings)))\n",
    "    return total_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_datat = get_data('train_sample/')\n",
    "validation_datat = get_data('val_sample/')\n",
    "testing_datat = get_data('test_sample/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_inputt=[]\n",
    "for i in range(len(training_datat)-WINDOWS):\n",
    "  xtrain_inputt.append(training_datat[i:i+WINDOWS,:])\n",
    "xtrain_inputt=np.array(xtrain_inputt)\n",
    "print(xtrain_inputt.shape)\n",
    "xtrain_inputt = xtrain_inputt.reshape(15222, WINDOWS, -1)\n",
    "\n",
    "xval_inputt=[]\n",
    "for i in range(len(validation_datat)-WINDOWS):\n",
    "  xval_inputt.append(validation_datat[i:i+WINDOWS,:])\n",
    "xval_inputt=np.array(xval_inputt)\n",
    "print(xval_inputt.shape)\n",
    "xval_inputt = xval_inputt.reshape(1654, WINDOWS, -1)\n",
    "\n",
    "xtest_inputt=[]\n",
    "for i in range(len(testing_datat)-WINDOWS):\n",
    "  xtest_inputt.append(testing_datat[i:i+WINDOWS,:])\n",
    "xtest_inputt=np.array(xtest_inputt)\n",
    "print(xtest_inputt.shape)\n",
    "xtest_inputt = xtest_inputt.reshape(2513, WINDOWS, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "    #return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def mcc_m(y_true, y_pred):\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
    "\n",
    "    num = tp * tn - fp * fn\n",
    "    den = (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)\n",
    "    return num / K.sqrt(den + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    " \n",
    "   # bce_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred, from_logits=False)\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=False, label_smoothing=0.1)\n",
    "    bce_loss = bce(y_true, y_pred)\n",
    "    mse_loss = tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
    "    loss = 0.85*bce_loss + 0.15*mse_loss\n",
    "    \n",
    "    return bce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, input_shapet):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    inputst = Input(shape=input_shapet)\n",
    "    x = TCN(nb_filters=16, return_sequences=True)(inputs)\n",
    "    x = LSTM(64, input_shape=(WINDOWS,21), return_sequences=True)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    for i in range(3):\n",
    "        x1 = TCN(nb_filters=16, return_sequences=True)(inputs)\n",
    "        x1 = LSTM(64, input_shape=(WINDOWS,21), return_sequences=True)(x1)\n",
    "        x1 = Dropout(0.3)(x1)\n",
    "        x1 = LSTM(32, return_sequences=True)(x1)\n",
    "        x1 = Dropout(0.3)(x1)\n",
    "        x1 = LSTM(16, return_sequences=True)(x1)\n",
    "        x1 = Dropout(0.3)(x1)\n",
    "        x = concatenate([x,x1],axis=-1)\n",
    "    \n",
    "    x = SeqSelfAttention(attention_activation='tanh')(x)\n",
    "    x = LSTM(16, return_sequences=False)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(16,kernel_initializer=\"uniform\",activation='relu')(x)\n",
    "    \n",
    "    xt = TCN(nb_filters=16, return_sequences=True)(inputst)\n",
    "    xt = Bidirectional(GRU(16, return_sequences=True))(xt)\n",
    "    xt = Dropout(0.3)(xt)\n",
    "    xt = Dense(16,kernel_initializer=\"uniform\",activation='relu')(xt)\n",
    "    \n",
    "    \n",
    "    for i in range(2):\n",
    "        x2 = TCN(nb_filters=16, return_sequences=True)(inputst)\n",
    "        x2 = Bidirectional(GRU(16, return_sequences=True))(x2)\n",
    "        x2 = Dropout(0.3)(x2)\n",
    "        \n",
    "      #  x2 = Dense(16,kernel_initializer=\"uniform\",activation='relu')(inputst)\n",
    "        xt = concatenate([xt,x2],axis=-1)\n",
    "        #x2 = Dense(16,kernel_initializer=\"uniform\",activation='relu')(xt)\n",
    "    \n",
    "    xt = Bidirectional(GRU(16, return_sequences=False))(xt)\n",
    "    xt = Dropout(0.3)(xt)\n",
    "    xt = Dense(8,kernel_initializer=\"uniform\",activation='relu')(xt)\n",
    "    x_all = concatenate([x, xt],axis=-1)\n",
    "  #  x_all = Dense(16,kernel_initializer=\"uniform\",activation='relu')(x_all)\n",
    "    x_final = Dense(1,kernel_initializer=\"uniform\",activation='relu')(x_all)\n",
    "    \n",
    "    model = Model(inputs=[inputs,inputst], outputs = x_final)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(input_shape=lstm_input.shape[1:], input_shapet=xtrain_inputt.shape[1:])\n",
    "model.compile(loss='binary_crossentropy',optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0005), metrics=['accuracy', f1_m, mcc_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 265574,
     "status": "ok",
     "timestamp": 1617821446582,
     "user": {
      "displayName": "Jiaying Gong",
      "photoUrl": "",
      "userId": "05239074792950850512"
     },
     "user_tz": 240
    },
    "id": "BcHzbgLYT8Ax",
    "outputId": "52928ad2-d86c-469c-e4ec-dd5709655f80"
   },
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    # keras.callbacks.EarlyStopping(patience=2),\n",
    "    keras.callbacks.ModelCheckpoint(filepath='modellstm.{epoch:02d}.h5'),\n",
    "    keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "history=model.fit(\n",
    "    [lstm_input,xtrain_inputt],\n",
    "    y,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    validation_data=([norm_X_val_input,xval_inputt], y_val),\n",
    "    verbose=1,\n",
    "    callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 261909,
     "status": "ok",
     "timestamp": 1617821446816,
     "user": {
      "displayName": "Jiaying Gong",
      "photoUrl": "",
      "userId": "05239074792950850512"
     },
     "user_tz": 240
    },
    "id": "u26QTDqWT8EG",
    "outputId": "311b7704-4bc9-4d11-896d-fd9709689ec3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 259510,
     "status": "ok",
     "timestamp": 1617821446817,
     "user": {
      "displayName": "Jiaying Gong",
      "photoUrl": "",
      "userId": "05239074792950850512"
     },
     "user_tz": 240
    },
    "id": "PduN-XEdT8HQ",
    "outputId": "8d65306a-75f3-4516-e3c0-83eb48f1265a"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 258177,
     "status": "ok",
     "timestamp": 1617821447482,
     "user": {
      "displayName": "Jiaying Gong",
      "photoUrl": "",
      "userId": "05239074792950850512"
     },
     "user_tz": 240
    },
    "id": "tL6Pm9sAT8KK",
    "outputId": "62676cc9-8b9e-48ec-f49b-bdd0b37dc7c3"
   },
   "outputs": [],
   "source": [
    "test_acc = model.evaluate([norm_X_test_input,xtest_inputt], y_test, batch_size = 32)\n",
    "#y_pred = model.predict_classes(norm_X_test_input,batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "executionInfo": {
     "elapsed": 49263,
     "status": "error",
     "timestamp": 1617813925488,
     "user": {
      "displayName": "Jiaying Gong",
      "photoUrl": "",
      "userId": "05239074792950850512"
     },
     "user_tz": 240
    },
    "id": "9UXhOlkNdKdq",
    "outputId": "6a4f57da-7c5d-4ec2-8fe2-31fcffe075c6"
   },
   "outputs": [],
   "source": [
    "#@tf.autograph.experimental.do_not_convert\n",
    "acc_hist = []\n",
    "n = 1\n",
    "for i in range(100):\n",
    "  k = str(n).zfill(2)\n",
    "  n += 1\n",
    "  name = 'modellstm.' + k +'.h5'\n",
    "  model11 = load_model(name, custom_objects={'SeqSelfAttention':SeqSelfAttention.get_custom_objects()['SeqSelfAttention'],'TCN':TCN,'f1_m':f1_m,'mcc_m':mcc_m,'custom_loss':custom_loss,'optim':optim})\n",
    "  model11.compile(loss='binary_crossentropy',optimizer='rmsprop', metrics=['accuracy', f1_m, mcc_m])\n",
    "  loss,acc,f1,mcc = model11.evaluate([norm_X_test_input,xtest_inputt],y_test,batch_size=32)\n",
    "  acc_hist.append(acc)\n",
    "  print(acc)\n",
    " \n",
    "    \n",
    "print(max(acc_hist))\n",
    "print(acc_hist.index(max(acc_hist))+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4373,
     "status": "ok",
     "timestamp": 1617813031897,
     "user": {
      "displayName": "Jiaying Gong",
      "photoUrl": "",
      "userId": "05239074792950850512"
     },
     "user_tz": 240
    },
    "id": "zacrNeQWMgCv",
    "outputId": "8af42c50-adda-40cd-af15-bcac41357752"
   },
   "outputs": [],
   "source": [
    "name = 'modellstm.58.h5'\n",
    "model11 = load_model(name, custom_objects={'SeqSelfAttention':SeqSelfAttention.get_custom_objects()['SeqSelfAttention'],'TCN':TCN,'f1_m':f1_m,'mcc_m':mcc_m,'custom_loss':custom_loss,'optim':optim})\n",
    "model11.compile(loss='binary_crossentropy',optimizer='rmsprop', metrics=['accuracy', f1_m, mcc_m])\n",
    "loss,acc,f1,mcc = model11.evaluate([norm_X_test_input,xtest_inputt],y_test,batch_size=32)\n",
    "print(acc)\n",
    "print(f1)\n",
    "print(mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "stock prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
